# CÃ€I Äáº¶T SPARK CLIENT TRÃŠN AIRFLOW MACHINE

## ğŸ” Váº¥n Ä‘á»

**SparkSubmitOperator** cáº§n `spark-submit` command cÃ³ sáºµn trÃªn mÃ¡y Airflow Ä‘á»ƒ submit jobs Ä‘áº¿n Spark cluster.

Hiá»‡n táº¡i:
- âœ… `spark_machine`: CÃ³ Spark installed (version 3.5.0)
- âŒ `airflow_machine`: KhÃ´ng cÃ³ Spark installed

## âœ… Giáº£i phÃ¡p: CÃ i Spark Client trÃªn Airflow Machine

### BÆ°á»›c 1: Download Spark

```bash
# TrÃªn airflow_machine
cd ~/Documents
wget https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz
tar -xzf spark-3.5.0-bin-hadoop3.tgz
sudo mv spark-3.5.0-bin-hadoop3 /opt/spark
```

### BÆ°á»›c 2: Set Environment Variables

```bash
# ThÃªm vÃ o ~/.bashrc hoáº·c ~/.profile
export SPARK_HOME=/opt/spark
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin

# Reload
source ~/.bashrc
```

### BÆ°á»›c 3: Verify Installation

```bash
# Kiá»ƒm tra spark-submit
spark-submit --version

# Kiá»ƒm tra cÃ³ thá»ƒ connect Ä‘áº¿n Spark cluster
spark-submit --master spark://192.168.1.134:7077 --version
```

### BÆ°á»›c 4: Update Airflow Connection (náº¿u cáº§n)

Trong Airflow UI:
- Admin â†’ Connections â†’ Edit `spark_default`
- Extra field:
  ```json
  {"master": "spark://192.168.1.134:7077"}
  ```

## ğŸ“ LÆ°u Ã½

1. **Chá»‰ cáº§n Spark Client**: KhÃ´ng cáº§n start Spark Master/Worker trÃªn Airflow machine
2. **SPARK_HOME**: Pháº£i Ä‘Æ°á»£c set Ä‘á»ƒ SparkSubmitOperator tÃ¬m tháº¥y
3. **Network**: Äáº£m báº£o Airflow machine cÃ³ thá»ƒ connect Ä‘áº¿n Spark Master (192.168.1.134:7077)

## ğŸ”§ Alternative: DÃ¹ng BashOperator

Náº¿u khÃ´ng muá»‘n cÃ i Spark trÃªn Airflow machine, cÃ³ thá»ƒ dÃ¹ng BashOperator Ä‘á»ƒ SSH vÃ o Spark machine vÃ  cháº¡y spark-submit tá»« Ä‘Ã³. NhÆ°ng cÃ¡ch nÃ y cáº§n SSH setup.

## âœ… Sau khi cÃ i

Sau khi cÃ i Spark client, SparkSubmitOperator sáº½ hoáº¡t Ä‘á»™ng vÃ  cÃ³ thá»ƒ submit jobs Ä‘áº¿n Spark cluster.


# KIá»‚M TRA Há»† THá»NG - CHECKLIST ÄÃP á»¨NG YÃŠU Cáº¦U

## ğŸ“‹ YÃŠU Cáº¦U Dá»° ÃN

### âœ… YÃŠU Cáº¦U 1: Chá»n Dataset tá»« Kaggle
**Tráº¡ng thÃ¡i:** âœ… **ÄÃƒ ÄÃP á»¨NG**

- **Dataset:** Credit Card Fraud Detection
- **Nguá»“n:** Kaggle
- **Váº¥n Ä‘á»:** Binary Classification (Fraud Detection)
- **Features:** Time, V1-V28 (PCA features), Amount, Class
- **KÃ­ch thÆ°á»›c:** 
  - Train: 199,365 records
  - Stream: 85,444 records

**Vá»‹ trÃ­ file:**
- `data/train.csv` - Training data
- `data/stream.csv` - Streaming data

**Kiá»ƒm tra:**
```bash
# Kiá»ƒm tra files tá»“n táº¡i
ls -lh data/train.csv data/stream.csv

# Kiá»ƒm tra sá»‘ dÃ²ng
wc -l data/train.csv data/stream.csv
```

---

### âœ… YÃŠU Cáº¦U 2: Chia dá»¯ liá»‡u thÃ nh 2 pháº§n
**Tráº¡ng thÃ¡i:** âœ… **ÄÃƒ ÄÃP á»¨NG**

- **Pháº§n 1 (Training):** `train.csv` - 199,365 records
- **Pháº§n 2 (Streaming):** `stream.csv` - 85,444 records

**Kiá»ƒm tra:**
```bash
# Kiá»ƒm tra train.csv
head -5 data/train.csv
tail -5 data/train.csv

# Kiá»ƒm tra stream.csv
head -5 data/stream.csv
tail -5 data/stream.csv

# Kiá»ƒm tra class distribution
grep -c ",1$" data/train.csv  # Fraud cases
grep -c ",0$" data/train.csv  # Normal cases
```

---

### âœ… YÃŠU Cáº¦U 3: Spark ML Training
**Tráº¡ng thÃ¡i:** âœ… **ÄÃƒ ÄÃP á»¨NG**

**Script:** `airflow_machine/scripts/train_model.py`

**Chá»©c nÄƒng:**
- âœ… Äá»c dá»¯ liá»‡u tá»« CSV
- âœ… Preprocessing (handle missing values, feature scaling)
- âœ… Training vá»›i RandomForest hoáº·c GBTClassifier
- âœ… Evaluation (AUC, Accuracy, Precision, Recall, F1)
- âœ… LÆ°u model vÃ  metrics

**Model Ä‘Æ°á»£c lÆ°u á»Ÿ Ä‘Ã¢u:**
- **Path:** `/tmp/fraud_models/fraud_detection_v1` (trÃªn Spark machine)
- **Format:** Spark ML PipelineModel
- **Files trong model folder:**
  - `metadata/` - Model metadata
  - `stages/` - Pipeline stages (VectorAssembler, StandardScaler, Model)
  - `metrics.json` - Training metrics

**Kiá»ƒm tra:**
```bash
# TrÃªn Spark machine
ls -lh /tmp/fraud_models/fraud_detection_v1/
cat /tmp/fraud_models/fraud_detection_v1/metrics.json
```

**Task trong DAG:** `train_model` (SparkSubmitOperator)

---

### âœ… YÃŠU Cáº¦U 4: Streaming Pipeline
**Tráº¡ng thÃ¡i:** âœ… **ÄÃƒ ÄÃP á»¨NG**

#### 4.1. Producer (MÃ´ phá»ng streaming)
**Script:** `airflow_machine/scripts/producer.py`

**Chá»©c nÄƒng:**
- âœ… Äá»c `stream.csv`
- âœ… Gá»­i messages vÃ o Kafka topic `input_stream`
- âœ… Rate limiting (configurable)
- âœ… JSON format

**Task trong DAG:** `start_producer` (BashOperator)

#### 4.2. Spark Streaming (Äá»c vÃ  Predict)
**Script:** `airflow_machine/scripts/streaming_inference.py`

**Chá»©c nÄƒng:**
- âœ… Äá»c tá»« Kafka topic `input_stream`
- âœ… Load trained model tá»« `/tmp/fraud_models/fraud_detection_v1`
- âœ… Predict vá»›i model
- âœ… Ghi káº¿t quáº£ vÃ o Kafka topic `prediction_output`
- âœ… Checkpointing cho fault tolerance

**Task trong DAG:** `start_spark_streaming` (SparkSubmitOperator)

#### 4.3. Visualization
**Script:** `airflow_machine/scripts/viewer.py`

**Chá»©c nÄƒng:**
- âœ… Äá»c predictions tá»« Kafka topic `prediction_output`
- âœ… Real-time dashboard vá»›i Streamlit
- âœ… Metrics: Total, Fraud, Normal, Fraud Rate
- âœ… Charts: Pie chart, Timeline
- âœ… Download predictions as CSV

**Task trong DAG:** `start_viewer` (BashOperator)

**Kiá»ƒm tra:**
```bash
# Kiá»ƒm tra producer
python3 airflow_machine/scripts/producer.py --help

# Kiá»ƒm tra streaming script
python3 airflow_machine/scripts/streaming_inference.py --help

# Kiá»ƒm tra viewer
streamlit run airflow_machine/scripts/viewer.py --help
```

---

### âš ï¸ YÃŠU Cáº¦U 5: Airflow Orchestration
**Tráº¡ng thÃ¡i:** âš ï¸ **Má»˜T PHáº¦N ÄÃP á»¨NG**

#### 5.1. Khá»Ÿi Ä‘á»™ng Kafka (Docker)
**Tráº¡ng thÃ¡i:** âš ï¸ **CHá»ˆ VERIFY, KHÃ”NG START**

**Hiá»‡n táº¡i:**
- Task `verify_kafka_ready` chá»‰ kiá»ƒm tra Kafka accessible
- Kafka pháº£i Ä‘Æ°á»£c start thá»§ cÃ´ng trÃªn Kafka machine: `cd kafka_machine && ./start.sh`

**Cáº§n bá»• sung:**
- Task Ä‘á»ƒ start Kafka Docker containers (náº¿u cáº§n)
- Hoáº·c giá»¯ nguyÃªn nhÆ° hiá»‡n táº¡i (manual start) vÃ¬ Kafka lÃ  long-running service

**Kiá»ƒm tra:**
```bash
# TrÃªn Kafka machine
cd kafka_machine
./start.sh

# Verify
docker ps | grep kafka
curl http://kafka-machine-ip:8080  # Kafka UI
```

#### 5.2. Cháº¡y Spark Server
**Tráº¡ng thÃ¡i:** âš ï¸ **CHá»ˆ VERIFY, KHÃ”NG START**

**Hiá»‡n táº¡i:**
- Task `verify_spark_ready` chá»‰ kiá»ƒm tra Spark Master accessible
- Spark pháº£i Ä‘Æ°á»£c start thá»§ cÃ´ng trÃªn Spark machine: `cd spark_machine && ./start.sh`

**Cáº§n bá»• sung:**
- Task Ä‘á»ƒ start Spark Master vÃ  Workers (náº¿u cáº§n)
- Hoáº·c giá»¯ nguyÃªn nhÆ° hiá»‡n táº¡i (manual start) vÃ¬ Spark lÃ  long-running service

**Kiá»ƒm tra:**
```bash
# TrÃªn Spark machine
cd spark_machine
./start.sh

# Verify
jps | grep -E "Master|Worker"
curl http://spark-machine-ip:8080  # Spark Web UI
```

#### 5.3. Cháº¡y Streaming Simulation
**Tráº¡ng thÃ¡i:** âœ… **ÄÃƒ ÄÃP á»¨NG**

**Task:** `start_producer` - Cháº¡y producer.py Ä‘á»ƒ gá»­i data vÃ o Kafka

#### 5.4. Submit Code Training
**Tráº¡ng thÃ¡i:** âœ… **ÄÃƒ ÄÃP á»¨NG**

**Task:** `train_model` - Submit train_model.py lÃªn Spark cluster

#### 5.5. Submit Code Prediction
**Tráº¡ng thÃ¡i:** âœ… **ÄÃƒ ÄÃP á»¨NG**

**Task:** `start_spark_streaming` - Submit streaming_inference.py lÃªn Spark cluster

---

## ğŸ“Š Tá»”NG Káº¾T ÄÃP á»¨NG YÃŠU Cáº¦U

| YÃªu cáº§u | Tráº¡ng thÃ¡i | Ghi chÃº |
|---------|-----------|---------|
| 1. Dataset tá»« Kaggle | âœ… | Credit Card Fraud Detection |
| 2. Chia dá»¯ liá»‡u train/stream | âœ… | train.csv vÃ  stream.csv |
| 3. Spark ML Training | âœ… | train_model.py vá»›i RandomForest/GBT |
| 4. Streaming Pipeline | âœ… | Producer â†’ Kafka â†’ Spark â†’ Kafka â†’ Viewer |
| 5.1. Start Kafka (Docker) | âš ï¸ | Chá»‰ verify, khÃ´ng start tá»± Ä‘á»™ng |
| 5.2. Start Spark Server | âš ï¸ | Chá»‰ verify, khÃ´ng start tá»± Ä‘á»™ng |
| 5.3. Run Streaming Simulation | âœ… | start_producer task |
| 5.4. Submit Training Code | âœ… | train_model task |
| 5.5. Submit Prediction Code | âœ… | start_spark_streaming task |

**Tá»•ng Ä‘iá»ƒm:** 7/9 yÃªu cáº§u Ä‘Ã£ Ä‘Ã¡p á»©ng Ä‘áº§y Ä‘á»§, 2 yÃªu cáº§u chá»‰ verify (cÃ³ thá»ƒ cháº¥p nháº­n vÃ¬ services lÃ  long-running)

---

## ğŸ“ MODEL ÄÆ¯á»¢C LÆ¯U á» ÄÃ‚U?

### Vá»‹ trÃ­ Model sau khi Training:

**TrÃªn Spark Machine:**
```
/tmp/fraud_models/fraud_detection_v1/
â”œâ”€â”€ metadata/
â”‚   â”œâ”€â”€ metadata/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ stages/
â”‚   â”œâ”€â”€ 0_VectorAssembler_xxx/
â”‚   â”œâ”€â”€ 1_StandardScaler_xxx/
â”‚   â””â”€â”€ 2_RandomForestClassifier_xxx/
â””â”€â”€ metrics.json
```

**Path trong DAG:**
```python
application_args=[
    '--output', f'{SPARK_MODELS_DIR}/fraud_detection_v1',
]
# Default: /tmp/fraud_models/fraud_detection_v1
```

**Kiá»ƒm tra Model:**
```bash
# TrÃªn Spark machine
ls -lh /tmp/fraud_models/fraud_detection_v1/
cat /tmp/fraud_models/fraud_detection_v1/metrics.json

# Kiá»ƒm tra model cÃ³ thá»ƒ load Ä‘Æ°á»£c khÃ´ng
python3 -c "
from pyspark.ml import PipelineModel
model = PipelineModel.load('/tmp/fraud_models/fraud_detection_v1')
print('Model loaded successfully!')
"
```

**Model Ä‘Æ°á»£c sá»­ dá»¥ng á»Ÿ Ä‘Ã¢u:**
- Streaming inference script load model tá»« path nÃ y:
  ```python
  --model-path file:///tmp/fraud_models/fraud_detection_v1
  ```

---

## ğŸ” HÆ¯á»šNG DáºªN KIá»‚M TRA Tá»ªNG QUÃ TRÃŒNH

### 1. Kiá»ƒm tra Dataset

```bash
# Kiá»ƒm tra files tá»“n táº¡i
cd /home/phanvantai/Documents/four_years/bigdata/the_end
ls -lh data/*.csv

# Kiá»ƒm tra sá»‘ dÃ²ng
wc -l data/train.csv data/stream.csv

# Kiá»ƒm tra header
head -1 data/train.csv
head -1 data/stream.csv

# Kiá»ƒm tra class distribution
echo "Train - Fraud cases:"
grep -c ",1$" data/train.csv
echo "Train - Normal cases:"
grep -c ",0$" data/train.csv
```

**Káº¿t quáº£ mong Ä‘á»£i:**
- train.csv: ~199,365 dÃ²ng
- stream.csv: ~85,444 dÃ²ng
- CÃ³ header vá»›i cÃ¡c columns: Time, V1-V28, Amount, Class

---

### 2. Kiá»ƒm tra Kafka

```bash
# TrÃªn Kafka machine
cd kafka_machine

# Start Kafka
./start.sh

# Kiá»ƒm tra containers
docker ps | grep -E "kafka|zookeeper"

# Kiá»ƒm tra topics
docker exec kafka kafka-topics.sh --list --bootstrap-server localhost:29092

# Kiá»ƒm tra Kafka UI
curl http://localhost:8080

# Test producer (tá»« Airflow machine)
python3 -c "
from kafka import KafkaProducer
import json
producer = KafkaProducer(
    bootstrap_servers='kafka-machine-ip:9092',
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)
producer.send('input_stream', {'test': 'data'})
producer.flush()
print('Message sent successfully!')
"
```

**Káº¿t quáº£ mong Ä‘á»£i:**
- Kafka containers running
- Topics: `input_stream`, `prediction_output`
- Kafka UI accessible
- Producer cÃ³ thá»ƒ gá»­i messages

---

### 3. Kiá»ƒm tra Spark Cluster

```bash
# TrÃªn Spark machine
cd spark_machine

# Start Spark
./start.sh

# Kiá»ƒm tra processes
jps | grep -E "Master|Worker"

# Kiá»ƒm tra Spark Web UI
curl http://localhost:8080

# Test Spark connection (tá»« Airflow machine)
spark-submit --master spark://spark-machine-ip:7077 --version

# Kiá»ƒm tra thÆ° má»¥c models vÃ  checkpoints
ls -ld /tmp/fraud_data /tmp/fraud_models /checkpoints
```

**Káº¿t quáº£ mong Ä‘á»£i:**
- Spark Master vÃ  Worker processes running
- Spark Web UI accessible
- CÃ³ thá»ƒ connect tá»« Airflow machine
- ThÆ° má»¥c models vÃ  checkpoints tá»“n táº¡i

---

### 4. Kiá»ƒm tra Training Process

```bash
# TrÃªn Airflow machine
cd airflow_machine

# Test training script locally (náº¿u cÃ³ Spark local)
spark-submit scripts/train_model.py \
    --input /tmp/fraud_data/train.csv \
    --output /tmp/fraud_models/test_model

# Hoáº·c cháº¡y qua Airflow DAG
# Trigger DAG â†’ Task: train_model

# Sau khi training, kiá»ƒm tra model
# TrÃªn Spark machine:
ls -lh /tmp/fraud_models/fraud_detection_v1/
cat /tmp/fraud_models/fraud_detection_v1/metrics.json
```

**Káº¿t quáº£ mong Ä‘á»£i:**
- Training job cháº¡y thÃ nh cÃ´ng
- Model Ä‘Æ°á»£c lÆ°u táº¡i `/tmp/fraud_models/fraud_detection_v1/`
- File `metrics.json` cÃ³ cÃ¡c metrics: AUC, Accuracy, Precision, Recall, F1

**Kiá»ƒm tra Metrics:**
```bash
cat /tmp/fraud_models/fraud_detection_v1/metrics.json
```

**Metrics mong Ä‘á»£i:**
- AUC: > 0.90 (tá»‘t)
- Accuracy: > 0.99 (do imbalanced data)
- Precision, Recall, F1: há»£p lÃ½

---

### 5. Kiá»ƒm tra Streaming Process

#### 5.1. Kiá»ƒm tra Producer

```bash
# TrÃªn Airflow machine
cd airflow_machine

# Test producer (khÃ´ng gá»­i thá»±c táº¿)
python3 scripts/producer.py --help

# Test producer vá»›i má»™t vÃ i records
head -10 data/stream.csv > /tmp/test_stream.csv
python3 scripts/producer.py \
    --input /tmp/test_stream.csv \
    --kafka-bootstrap kafka-machine-ip:9092 \
    --topic input_stream \
    --rate 1

# Kiá»ƒm tra messages trong Kafka
# TrÃªn Kafka machine:
docker exec kafka kafka-console-consumer.sh \
    --bootstrap-server localhost:29092 \
    --topic input_stream \
    --from-beginning \
    --max-messages 5
```

**Káº¿t quáº£ mong Ä‘á»£i:**
- Producer gá»­i messages thÃ nh cÃ´ng
- Messages cÃ³ format JSON Ä‘Ãºng
- Messages xuáº¥t hiá»‡n trong Kafka topic

#### 5.2. Kiá»ƒm tra Spark Streaming

```bash
# TrÃªn Airflow machine
# Trigger DAG â†’ Task: start_spark_streaming

# Kiá»ƒm tra Spark Web UI
# Má»Ÿ browser: http://spark-machine-ip:8080
# Xem tab "Streaming" â†’ Job "FraudDetectionStreaming"

# Kiá»ƒm tra logs
# Trong Airflow UI â†’ Task logs â†’ start_spark_streaming

# Kiá»ƒm tra checkpoint
# TrÃªn Spark machine:
ls -lh /checkpoints/streaming_inference/
```

**Káº¿t quáº£ mong Ä‘á»£i:**
- Spark streaming job RUNNING
- Äá»c messages tá»« Kafka topic `input_stream`
- Predict vÃ  ghi vÃ o Kafka topic `prediction_output`
- Checkpoint Ä‘Æ°á»£c táº¡o

#### 5.3. Kiá»ƒm tra Predictions trong Kafka

```bash
# TrÃªn Kafka machine
docker exec kafka kafka-console-consumer.sh \
    --bootstrap-server localhost:29092 \
    --topic prediction_output \
    --from-beginning \
    --max-messages 10
```

**Káº¿t quáº£ mong Ä‘á»£i:**
- Messages cÃ³ format JSON vá»›i cÃ¡c fields:
  - `transaction_id`
  - `timestamp`
  - `prediction` (0 hoáº·c 1)
  - `probability`
  - `model_version`
  - `prediction_timestamp`

---

### 6. Kiá»ƒm tra Visualization

```bash
# TrÃªn Airflow machine
cd airflow_machine

# Start viewer
streamlit run scripts/viewer.py --server.port 8501

# Má»Ÿ browser: http://airflow-machine-ip:8501

# Hoáº·c trigger DAG â†’ Task: start_viewer
```

**Kiá»ƒm tra Dashboard:**
- âœ… Total Predictions counter tÄƒng dáº§n
- âœ… Fraud Detected counter hiá»ƒn thá»‹ Ä‘Ãºng
- âœ… Pie chart hiá»ƒn thá»‹ distribution
- âœ… Timeline chart hiá»ƒn thá»‹ predictions theo thá»i gian
- âœ… Table hiá»ƒn thá»‹ recent predictions
- âœ… Download CSV button hoáº¡t Ä‘á»™ng

---

### 7. Kiá»ƒm tra ToÃ n bá»™ Pipeline qua Airflow

```bash
# TrÃªn Airflow machine
cd airflow_machine

# Start Airflow
./start.sh

# Má»Ÿ browser: http://airflow-machine-ip:8080
# Login: admin/admin

# Trigger DAG: fraud_detection_pipeline

# Monitor tasks:
# 1. verify_scripts â†’ SUCCESS
# 2. verify_kafka_ready â†’ SUCCESS
# 3. verify_spark_ready â†’ SUCCESS
# 4. verify_data_files â†’ SUCCESS
# 5. train_model â†’ SUCCESS (cÃ³ thá»ƒ máº¥t 5-10 phÃºt)
# 6. start_spark_streaming â†’ SUCCESS (job RUNNING)
# 7. verify_streaming_running â†’ SUCCESS
# 8. start_producer â†’ SUCCESS (gá»­i messages)
# 9. start_viewer â†’ SUCCESS (dashboard accessible)
```

**Kiá»ƒm tra Logs:**
- Click vÃ o tá»«ng task â†’ View Log
- Kiá»ƒm tra cÃ³ lá»—i khÃ´ng
- Kiá»ƒm tra output messages

---

## ğŸ› TROUBLESHOOTING CHECKLIST

### Náº¿u Training fail:
- [ ] Kiá»ƒm tra train.csv tá»“n táº¡i trÃªn Spark machine táº¡i `/tmp/fraud_data/`
- [ ] Kiá»ƒm tra Spark cluster Ä‘ang running
- [ ] Kiá»ƒm tra permissions trÃªn `/tmp/fraud_models/`
- [ ] Xem logs trong Airflow UI

### Náº¿u Streaming fail:
- [ ] Kiá»ƒm tra model Ä‘Ã£ Ä‘Æ°á»£c train chÆ°a
- [ ] Kiá»ƒm tra Kafka Ä‘ang running
- [ ] Kiá»ƒm tra Spark streaming job RUNNING
- [ ] Kiá»ƒm tra checkpoint directory cÃ³ quyá»n write

### Náº¿u Producer fail:
- [ ] Kiá»ƒm tra stream.csv tá»“n táº¡i
- [ ] Kiá»ƒm tra Kafka accessible
- [ ] Kiá»ƒm tra topic `input_stream` Ä‘Ã£ Ä‘Æ°á»£c táº¡o

### Náº¿u Viewer khÃ´ng hiá»ƒn thá»‹ data:
- [ ] Kiá»ƒm tra Spark streaming Ä‘ang cháº¡y
- [ ] Kiá»ƒm tra Producer Ä‘Ã£ gá»­i messages
- [ ] Kiá»ƒm tra Kafka topic `prediction_output` cÃ³ messages
- [ ] Kiá»ƒm tra Kafka connection trong viewer.py

---

## âœ… CHECKLIST TRÆ¯á»šC KHI DEMO

- [ ] Dataset Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh train.csv vÃ  stream.csv
- [ ] Kafka Ä‘Ã£ Ä‘Æ°á»£c start vÃ  topics Ä‘Ã£ Ä‘Æ°á»£c táº¡o
- [ ] Spark cluster Ä‘Ã£ Ä‘Æ°á»£c start
- [ ] Airflow Ä‘Ã£ Ä‘Æ°á»£c start vÃ  DAG visible
- [ ] Airflow Connection `spark_default` Ä‘Ã£ Ä‘Æ°á»£c config
- [ ] train.csv Ä‘Ã£ Ä‘Æ°á»£c copy lÃªn Spark machine táº¡i `/tmp/fraud_data/`
- [ ] ThÆ° má»¥c `/tmp/fraud_models/` vÃ  `/checkpoints/` Ä‘Ã£ Ä‘Æ°á»£c táº¡o vá»›i permissions Ä‘Ãºng
- [ ] Network connectivity giá»¯a cÃ¡c machines OK
- [ ] Firewall rules Ä‘Ã£ Ä‘Æ°á»£c má»Ÿ

---

## ğŸ“ GHI CHÃš QUAN TRá»ŒNG

1. **Kafka vÃ  Spark lÃ  long-running services:** NÃªn start thá»§ cÃ´ng trÆ°á»›c khi cháº¡y pipeline, khÃ´ng cáº§n start tá»± Ä‘á»™ng trong DAG.

2. **Model path:** Model Ä‘Æ°á»£c lÆ°u trÃªn Spark machine táº¡i `/tmp/fraud_models/fraud_detection_v1/`. Äáº£m báº£o path nÃ y cÃ³ quyá»n write.

3. **Data files:** 
   - `train.csv` pháº£i á»Ÿ trÃªn Spark machine táº¡i `/tmp/fraud_data/train.csv`
   - `stream.csv` pháº£i á»Ÿ trÃªn Airflow machine táº¡i `data/stream.csv`

4. **Checkpoints:** Spark streaming checkpoint táº¡i `/checkpoints/streaming_inference/` trÃªn Spark machine.

5. **Network:** Äáº£m báº£o cÃ¡c machines cÃ³ thá»ƒ communicate vá»›i nhau qua network.

